# âœ… Tehomia Diagnostic GPT Interface (Unified and Executable)

from openai import OpenAI
import os
from dotenv import load_dotenv

def run_diagnostics():
    print("âœ… MAIN.PY LOADED â€” Running...\n")

    # ğŸ§¬ Load environment and check key
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    print("ğŸ” Loaded API Key:", "YES" if api_key else "NO")

    if not api_key:
        print("âŒ ERROR: No API key loaded. Check .env file.")
        return

    # ğŸ§  Initialize client
    client = OpenAI(api_key=api_key)

    # ğŸ§ª Sample diagnostic payload
    diagnostic_messages = [
        {
            "role": "system",
            "content": "You are a diagnostic-bound assistant. Your role is to trace and expose handler-to-UI propagation flaws using structured debug output."
        },
        {
            "role": "user",
            "content": "Generate a sample recipe object and output:\nğŸ“¦ Pipeline Debug - Cuisine\nğŸ“„ Pipeline Debug - Title\nğŸ–¼ï¸ Pipeline Debug - Static Image\nğŸš€ Final Response JSON"
        }
    ]

    # ğŸš€ Execute call with checkpoints
    try:
        print("ğŸ“¡ Sending request to GPT...")
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=diagnostic_messages,
            temperature=0.2
        )
        print("ğŸ“¨ Got response, printing now...\n")
        print(response.choices[0].message.content)

    except Exception as e:
        print("âŒ GPT CALL FAILED:")
        print(e)

# ğŸ” Trigger when script is run directly
if __name__ == "__main__
